#!/user/bin/env python3

"""
Goes through the log file from the training
of all models (for each cell type, a model is trained)
and produces summary statistics for each metric
(e.g. training time, best epoch for valid avgAUPR/avgAUC
test avgAUPR, etc.) from a training run.

We assume that the directory structure of the folder
specified by save_root was generated by train.py
If the way reuslts are stored changes,
this needs to change too!
"""

import subprocess
import numpy as np
import copy
import argparse
import os


def tail(f:str, n: int):
    """
    Params
    f: str - path to file
    n: int - last n lines
    Returns list of strings, each string is line of input
    Adapted from https://stackoverflow.com/a/136280

    If n >= number of lines in the file, all lines get returned

    If file is empty, for any n, empty list returned
    """
    proc = subprocess.Popen(['tail', '-n', str(n), f], stdout=subprocess.PIPE)
    lines = proc.stdout.readlines()
    return [l.decode() for l in lines]

def compute_summary_stats(arr: np.ndarray, axis=None):
    """
    Compute mean, median, variance, min, and max
    for the metric in input array.
    Input array has a metric from the model
    of each cell type.
    """
    summary_func_args = {
        'a': arr,
        'axis': axis,
    }
    return np.mean(**summary_func_args), \
        np.median(**summary_func_args), \
        np.var(**summary_func_args), \
        np.min(**summary_func_args), \
        np.max(**summary_func_args)

parser = argparse.ArgumentParser(description='Summarize metrics in log files from train-over-cell-types.sh')
parser.add_argument('save_root', type=str,
    help='path to folder where results were saved in; '
    'should be the same as the value of --save-dir '
    'passed to v2PyTorch/train.py'
)
parser.add_argument('--model_type', type=str, default='attchrome', help='DeepDiff variation')
args = parser.parse_args()

# Check all 56 cell types present
expected_num_cell_types = 56
cell_types = sorted(os.listdir(args.save_root))
assert len(cell_types) == expected_num_cell_types, \
    'number of cell types not equal to expected! ' \
    'len(cell_types) = ' + str(len(cell_types))

last_n_lines_needed = 14

# position in lines array that the metric is in
offsets = {
    'finished_training_text': 0,
    'training_time': 1,
    'best_valid_avgAUPR': {
        'best_epoch': 2,
        'best_valid_avgAUPR': 3,
        'best_test_avgAUPR': 4,
        'copypaste': 6,
    },
    'best_valid_avgAUC': {
        'best_epoch': 8,
        'best_valid_avgAUC': 9,
        'best_test_avgAUC': 10,
        'copypaste': 12,
    },
    'model_name': 13,
}

# accumulate metrics
training_time_acc = []
base_acc = {
    'best_epoch': [],
    'copypaste': [],
}
acc = {
    'best_valid_avgAUPR': copy.deepcopy(base_acc),
    'best_valid_avgAUC': copy.deepcopy(base_acc),
}

summary_stats = {
    'best_valid_avgAUPR': copy.deepcopy(base_acc),
    'best_valid_avgAUC': copy.deepcopy(base_acc),
}

copypaste = {
    'best_valid_avgAUPR': '',
    'best_valid_avgAUC': '',
}

# iterate over all files
# parse out lines
# get the info from the file specific to a cell
# append to appropriate array
for cell_type in cell_types:
    model_name = cell_type + '_' + args.model_type
    log_file_name = model_name + '.log'
    log_file_path = os.path.join(args.save_root, cell_type, model_name, log_file_name)
    print('On:', log_file_path)
    # get the last lines needed
    lines = tail(log_file_path, last_n_lines_needed)
    # Check that the all lines retrived
    assert len(lines) == last_n_lines_needed, \
        'number of lines from tail not equal to what was requested! ' \
        'len(lines) = ' + str(len(lines))
    # Check that first and last line are as expected
    finished_training_line = lines[offsets['finished_training_text']].strip()
    assert finished_training_line == 'Finished training', \
        'first line not equal to expected! ' \
        'first line: ' + finished_training_line
    model_name_line = lines[offsets['model_name']].strip()
    assert model_name_line == 'the model name:  ' + model_name, \
        'last line not equal to expected! ' \
        'last line: ' + model_name_line
    # parse out info we want
    training_time = float(lines[offsets['training_time']].split(':')[-1].strip())
    training_time_acc.append(training_time)

    best_epoch_valid_avgAUPR = int(lines[offsets['best_valid_avgAUPR']['best_epoch']].split(':')[-1].strip())
    acc['best_valid_avgAUPR']['best_epoch'].append(best_epoch_valid_avgAUPR)

    best_epoch_valid_avgAUC = int(lines[offsets['best_valid_avgAUC']['best_epoch']].split(':')[-1].strip())
    acc['best_valid_avgAUC']['best_epoch'].append(best_epoch_valid_avgAUC)

    # split copy_paste and append to arr
    copypaste_best_valid_avgAUPR = [float(f) for f in lines[offsets['best_valid_avgAUPR']['copypaste']].split(',')]
    acc['best_valid_avgAUPR']['copypaste'].append(copypaste_best_valid_avgAUPR)

    copypaste_best_valid_avgAUC = [float(f) for f in lines[offsets['best_valid_avgAUC']['copypaste']].split(',')]
    acc['best_valid_avgAUC']['copypaste'].append(copypaste_best_valid_avgAUC)

# turn everything into numpy arrays
training_time_acc = np.array(training_time_acc)
for best_k, best_dict in acc.items():
    for k, lst in best_dict.items():
        acc[best_k][k] = np.array(lst)

# compute summary statistics
training_time_sum_stats = compute_summary_stats(training_time_acc)
total_training_time_hrs = np.round(np.sum(training_time_acc)/60, 4)

for best_k, best_dict in acc.items():
    # tuple
    summary_stats[best_k]['best_epoch'] = compute_summary_stats(acc[best_k]['best_epoch'])
    # tuple
    summary_stats[best_k]['copypaste'] = compute_summary_stats(acc[best_k]['copypaste'], axis=0)
    # shape (num_summary_stats, num_metrics_in_copypaste_in_log_file_for_avgAUPR)
    # a column is the summary stats for a metric (e.g. avg of test_avgAUPR's,
    # min of test_avgAUPR's, etc.)
    stacked = np.stack(summary_stats[best_k]['copypaste'], axis=0)
    # for each metric, get summary stats (e.g. avg of test_avgAUPR's,
    # min of test_avgAUPR's, etc.)
    # and convert them to ndarray of strings with floats
    # rounded to four significant figures
    copypastes_for_metrics = [','.join(np.char.mod('%.4g', stacked[:, i])) for i in range(stacked.shape[1])]
    # print copypaste for model best_valid_avgAUPR/best_valid_avgAUC
    print(best_k, 'copypaste:')
    print(','.join([str(round(f, 4)) for f in summary_stats[best_k]['best_epoch']] + copypastes_for_metrics))


# training time copy paste
training_time_copypaste = ','.join([str(total_training_time_hrs)] + list(np.char.mod('%.4g', training_time_sum_stats)))
print('training time copy paste (not a characteristic of a saved best model)')
print(training_time_copypaste)